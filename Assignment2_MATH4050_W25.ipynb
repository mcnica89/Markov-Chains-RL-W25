{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz4uTwW3Qw6YyKQNbn/42P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcnica89/Markov-Chains-RL-W25/blob/main/Assignment2_MATH4050_W25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PIG Policies\n",
        "\n",
        "Recall the 1-player-1-round version of the dice game PIG played with a 6 sided dice and where you go bust on rolling a \"1\". In this assignment you will implement policies for this game and then use this to calculate things about them. A policy for PIG can be encoded as a binary sequence:\n",
        "\n",
        "$$\\pi = [\\pi(0), \\pi(1), \\ldots, \\pi(s_{max})]$$\n",
        "\n",
        "where we use the convention that a 1 means \"ROLL AGAIN\" and a 0 means \"STOP\"\n",
        "\n",
        "$$\\pi(s) = \\begin{cases} 1, \\text{ when we ROLL when at state }s \\\\ 0, \\text{ when we STOP when at state }s \\end{cases}$$\n",
        "\n",
        "and where $s_{max}$ is the largest possible point value we will consider (as in Assignment 1, if our point value ever goes larger than $s_{max}$ we will keep the state at $s_{max}$). For example, the roll-below-k policy from class/Numberphile video corresponds to $\\pi = [\\underbrace{1,\\ldots,1}_{k \\text{ times}},0,0,...0]$\n",
        "\n",
        "## Part a)\n",
        "\n",
        "Write a function that inputs the policy $\\pi$, and outputs the probability transition matrix $M$ for what happens when you follow policy $\\pi$.  *Hint*: What are the terminal states here? There are potentially quite a few!\n",
        "\n",
        "**Important Computing Convention for All Parts of this Problem:** We will use indicies ```0``` to ```s_max+1``` for the state of \"being at point value $s$. (Since the policy $\\pi$ is given, we know for sure whether or not we will roll again or not at $s$) We will use a *special extra index* at the end to represent the \"Busted state\". Therefore the matrix you will return is a matrix of size $s_{max}+2,s_{max}+2$. You can acess this last state by using a ```-1``` as the index, for example if ```p``` is a probability vector, then ```p[-1]``` will be the probability we are in the busted state. (Alternatively you can access it the normal way by doing ```p[s_max+1]```). **Warning:** Be extra careful with this special index! Its easy to have a bug where you accidently use the special busted state as a regular state. For example a command like ```M[x,x+1]=0.5```, which normally represents moving from position $x$ to position $x+1$ with probaility 50%, will be incorrect when $x=s_{max}$.\n",
        "\n",
        "\n",
        "### Inputs:\n",
        "\n",
        "```policy``` = A numpy vector of length $s_{max}+1$ representing the policy $\\pi$. The entries are all 0s or 1s representing to roll again or stop at each state.\n",
        "\n",
        "### Outputs:\n",
        "\n",
        "```transition_matrix``` = The probability transition matrix for how you move when you follow policy $\\pi$, represented by an $s_{max}+2,s_{max}+2$ array in numpy. The last row/last column of the matrix correspond to the \"busted\" state. *Reminder:* Like in Assignment 1 Question 1, if the game would ever try to enter a point total larger than $s_{max}$, we just move to the point total $s_{max}$ instead.\n"
      ],
      "metadata": {
        "id": "GrAsGuE1nE9r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wg5H6ZSnEYv"
      },
      "outputs": [],
      "source": [
        "def policy_transition_matrix(policy):\n",
        "  #Inputs: policy is a numpy array of shape (s_max+1,) consisting of 1s and 0s\n",
        "  #Outputs: A transition_matrix of shape (s_max+2,s_max+2)\n",
        "\n",
        "  s_max = len(policy)-1 #infer s_max from the length of the policy given\n",
        "  busted_state_ix = s_max+1 #the index of the special busted state\n",
        "\n",
        "  transition_matrix = np.zeros((s_max+2,s_max+2))\n",
        "  #\n",
        "  # Your code here\n",
        "  #\n",
        "  return transition_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Stuff"
      ],
      "metadata": {
        "id": "DtBs2tYwxRTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Part b),c),d) you will use the transition matrix to calculate various things. All of these questions should be solved by using value iteration the (baby) Bellman equation and setting things up to get what you need. (*Note*: Please do not submit any Monte Carlo simulations to answer the question. However, it is ok to use Monte Carlo simulations to check your answers as you go if you want to!)\n",
        "\n",
        "# Part b)\n",
        "\n",
        "Write a function that calculates the probabaility to go bust when you play PIG and follow the policy $\\pi$. *Hint:* This is a bit like the Drunkard's Walk problem of finding the probability the drunkard would fall off the cliff\n"
      ],
      "metadata": {
        "id": "kV5qn4lHru7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def probability_to_go_bust(policy):\n",
        "  #Inputs: policy is a numpy array of shape (s_max+1,) consisting of 1s and 0s\n",
        "  #Outputs: A number which is the probability to go bust when following the policy.\n",
        "\n",
        "  s_max = len(policy)-1 #infer s_max from the length of the policy given\n",
        "  busted_state_ix = s_max+1 #the index of the special busted state\n",
        "\n",
        "  #you can use your transition matrix from part a) if you want to\n",
        "  transition_matrix = policy_transition_matrix(policy)\n",
        "\n",
        "  P_bust = 0.0\n",
        "  #\n",
        "  # Your code here\n",
        "  #\n",
        "  return P_bust"
      ],
      "metadata": {
        "id": "NeOsmltAtlrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part c)\n",
        "\n",
        "\n",
        "Write a function that calculates the expected number of turns until the round is over following $\\pi$ (either from going Bust or when the player \"wins\" by choosing to Stop rolling). *Hint:* This is a bit like we did in Snakes and Ladders with the appropriate modifications.\n"
      ],
      "metadata": {
        "id": "6-eVkQSUwOSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expected_number_of_turns(policy):\n",
        "  #Inputs: policy is a numpy array of shape (s_max+1,) consisting of 1s and 0s\n",
        "  #Outputs: A number which is the expected number of rounds of the game when following the policy.\n",
        "\n",
        "  s_max = len(policy)-1 #infer s_max from the length of the policy given\n",
        "  busted_state_ix = s_max+1 #the index of the special busted state\n",
        "\n",
        "  #you can use your transition matrix from part a) if you want to\n",
        "  transition_matrix = policy_transition_matrix(policy)\n",
        "\n",
        "  E_turns = 0.0\n",
        "  #\n",
        "  # Your code here\n",
        "  #\n",
        "  return E_turns"
      ],
      "metadata": {
        "id": "URDWN9iNwNpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part d)\n",
        "\n",
        "\n",
        "Write a function that calculates your expected score (i.e the expected number of banked points you have at the end) when you play PIG and follow the policy $\\pi$. *Hint:* You can check your work by re-creating the graph of the expected values for all the roll-under-k policies shown in the Numberphile video"
      ],
      "metadata": {
        "id": "5vqpS0oHt2XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expected_score(policy):\n",
        "  #Inputs: policy is a numpy array of shape (s_max+1,) consisting of 1s and 0s\n",
        "  #Outputs: A number which is the expected number of points you get in the game when following the policy.\n",
        "\n",
        "  s_max = len(policy)-1 #infer s_max from the length of the policy given\n",
        "  busted_state_ix = s_max+1 #the index of the special busted state\n",
        "\n",
        "  #you can use your transition matrix from part a) if you want to\n",
        "  transition_matrix = policy_transition_matrix(policy)\n",
        "\n",
        "  E_score = 0.0\n",
        "  #\n",
        "  # Your code here\n",
        "  #\n",
        "  return E_score"
      ],
      "metadata": {
        "id": "eF8KY1T0uMF5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}