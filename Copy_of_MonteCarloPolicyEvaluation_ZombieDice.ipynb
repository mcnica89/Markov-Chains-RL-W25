{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4A+2TMtb8BqKutoDaecQ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcnica89/Markov-Chains-RL-W25/blob/main/Copy_of_MonteCarloPolicyEvaluation_ZombieDice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "np.set_printoptions(precision=2)"
      ],
      "metadata": {
        "id": "qwlBxc1sr5ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulation"
      ],
      "metadata": {
        "id": "_Exf3QP2VHVX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AhshoGbk_rO"
      },
      "outputs": [],
      "source": [
        "#brains shotguns\n",
        "max_brains = 9 #there are only 13 dice! so max score is 13.\n",
        "max_shotguns = 2 #you immediatly lose if you exceed this!\n",
        "\n",
        "def num_to_words(my_array):\n",
        "    words = ['Brain', 'Shotgun', 'Feet']\n",
        "\n",
        "    # Using nditer to handle multi-dimensional arrays\n",
        "    result = np.empty_like(my_array, dtype=object)\n",
        "\n",
        "    it = np.nditer(my_array, flags=['multi_index'])\n",
        "    for idx in it:\n",
        "        result[it.multi_index] = words[int(my_array[it.multi_index])]\n",
        "\n",
        "    return result\n",
        "\n",
        "def dice_roll_history(): #secret!\n",
        "  '''Returns a list of all the outcomes of the dice using the code 0=Brain, 1=Shotgun, 2=Feet'''\n",
        "  dice_types = np.array([3,4,6]) #number of each type of dice\n",
        "  dice_probs = 1.0/6.0*np.array([[1,3,2],[2,2,2],[3,1,2]]) #the number of sides of each type on the 3 dice types.\n",
        "  #order is brains,shotguns,feet\n",
        "\n",
        "  t_max = np.sum(dice_types)-3 #this is the maximum length we can be gaurenteed to not run out of dice for.\n",
        "\n",
        "  history = np.ones((t_max,3),dtype=int)\n",
        "  def draw_a_new_dice():\n",
        "    '''returns a new dice from the box, one of the three types, and removes it from dice_types'''\n",
        "    nonlocal dice_types\n",
        "    #print(f\"{dice_types=}\")\n",
        "    p_dice = dice_types/np.sum(dice_types)\n",
        "    #print(p_dice)\n",
        "    choice = np.random.choice( 3,p=p_dice)\n",
        "    dice_types[choice] -= 1\n",
        "    if np.sum(dice_types) == 0:\n",
        "      dice_types = np.array([3,4,6]) #refill the cup if needed\n",
        "    return choice\n",
        "\n",
        "  def roll_a_dice(dice_type):\n",
        "    '''roll a dice of type dice_type and return the result order is brains, shotgun, feet'''\n",
        "    return np.random.choice( 3,p=dice_probs[dice_type])\n",
        "\n",
        "  #intialize by drawing three dice\n",
        "  current_dice = np.array([draw_a_new_dice() for i in range(3)])\n",
        "\n",
        "  #roll dice to create a history\n",
        "  for t in range(t_max):\n",
        "    for i in range(3):\n",
        "      this_roll =  int(roll_a_dice(current_dice[i]))\n",
        "      history[t,i] = this_roll\n",
        "      if this_roll == 0 or this_roll == 1: #for brains or shotguns, draw a new dice\n",
        "        current_dice[i] = draw_a_new_dice()\n",
        "  return history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_history = dice_roll_history()\n",
        "print(num_to_words(my_history))\n",
        "print(my_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIeQ65AZ6ysL",
        "outputId": "e6fb450b-cb5e-4c1c-d5e7-47cf2f92395e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Brain' 'Feet' 'Shotgun']\n",
            " ['Brain' 'Brain' 'Shotgun']\n",
            " ['Shotgun' 'Brain' 'Brain']\n",
            " ['Feet' 'Brain' 'Shotgun']\n",
            " ['Feet' 'Shotgun' 'Feet']\n",
            " ['Brain' 'Shotgun' 'Feet']\n",
            " ['Brain' 'Brain' 'Brain']\n",
            " ['Brain' 'Shotgun' 'Brain']\n",
            " ['Brain' 'Shotgun' 'Feet']\n",
            " ['Feet' 'Brain' 'Brain']]\n",
            "[[0 2 1]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [2 0 1]\n",
            " [2 1 2]\n",
            " [0 1 2]\n",
            " [0 0 0]\n",
            " [0 1 0]\n",
            " [0 1 2]\n",
            " [2 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Policy Evalution"
      ],
      "metadata": {
        "id": "N5NvEBmoVJC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Policy evaluation! ###\n",
        "\n",
        "# Setup number of episodes and maximum length of an episode\n",
        "num_epsiodes = 10_000\n",
        "t_max = 10\n",
        "\n",
        "# Setup the value function\n",
        "v = np.zeros((max_brains+1,max_shotguns+1))\n",
        "\n",
        "# Setup the policy! Policy is fixed for now.\n",
        "policy = np.zeros((max_brains+1,max_shotguns+1)) #where to roll again and where to stop.\n",
        "brains,shotguns = np.indices((max_brains+1,max_shotguns+1))\n",
        "policy[brains,shotguns] = (brains < 6) #reroll if brains<5 otherwise stop\n",
        "\n",
        "\n",
        "# Number of visits to each state.\n",
        "visits = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "\n",
        "# Main Monte Carlo loop\n",
        "\n",
        "verbose = False #whether or not to output text as we go\n",
        "for episode in tqdm(range(num_epsiodes)):\n",
        "  # Start a new epsiode!\n",
        "  if verbose: print(f\"Episode #{episode}...\")\n",
        "  this_episode_visits = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "  brain_state = int(0) #starting state of the number of brains, shotguns we've seen.\n",
        "  shotgun_state = int(0)\n",
        "  my_history = dice_roll_history() #generates all the rolls we need for the episode\n",
        "\n",
        "  for t in range(t_max): #go through the rounds t.\n",
        "    if verbose: print(f\".{t=}, Brains:{brain_state}, Shotguns:{shotgun_state}\")\n",
        "    this_episode_visits[brain_state,shotgun_state] += 1\n",
        "\n",
        "    if policy[brain_state,shotgun_state] == 1:\n",
        "      if verbose: print(f\"..Chose to Reroll! Roll={num_to_words(my_history[t])}\")\n",
        "      #chose to roll again!\n",
        "      num_brains = np.sum(my_history[t] == 0)\n",
        "      num_shotguns = np.sum(my_history[t] == 1)\n",
        "      brain_state += num_brains\n",
        "      shotgun_state += num_shotguns\n",
        "\n",
        "      # if we get too many shotguns, we lose.\n",
        "      if shotgun_state > max_shotguns:\n",
        "        if verbose:print(\"Went bust :(\")\n",
        "        break\n",
        "\n",
        "    elif policy[brain_state,shotgun_state] == 0:\n",
        "      if verbose:print(f\"..Chose to Stop! Final Brains={brain_state}\")\n",
        "      #chose to stop\n",
        "      break\n",
        "\n",
        "  #calculate final rewards here\n",
        "  if shotgun_state <= max_shotguns:\n",
        "    reward = brain_state\n",
        "  else:\n",
        "    reward = 0\n",
        "\n",
        "  #update the number of visits to each state and the running average of v.\n",
        "  v = np.where(this_episode_visits,v + 1/(visits+1)*(reward - v),v)\n",
        "  visits = np.where(this_episode_visits,visits+1,visits)\n",
        "\n",
        "  if verbose:print(f\"{v=}\")\n",
        "\n",
        "print(f\"Policy: \\n{policy}\")\n",
        "print(f\"v \\n{v}\")\n",
        "print(f\"visits \\n{visits}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFJy26b0r6kL",
        "outputId": "8670446e-1b11-489f-85ee-28a3221045d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:23<00:00, 430.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Policy: \n",
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "v \n",
            "[[1.15 0.49 0.16]\n",
            " [1.54 0.81 0.27]\n",
            " [2.4  1.28 0.41]\n",
            " [3.09 1.99 0.76]\n",
            " [4.18 2.8  1.43]\n",
            " [5.57 4.52 1.96]\n",
            " [6.   6.   6.  ]\n",
            " [7.   7.   7.  ]\n",
            " [8.   8.   8.  ]\n",
            " [0.   0.   0.  ]]\n",
            "visits \n",
            "[[10000  1017   995]\n",
            " [ 1273  2580  1754]\n",
            " [ 1550  2283  1647]\n",
            " [  884  1307  1777]\n",
            " [  420  1048  1397]\n",
            " [  224   681  1023]\n",
            " [  134   361   704]\n",
            " [   36   182   278]\n",
            " [   10    40    49]\n",
            " [    0     0     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Policy Improvement"
      ],
      "metadata": {
        "id": "ir6mQKmzVLM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Policy improvement!\n",
        "\n",
        "# Setup number of episodes and maximum length of an episode\n",
        "num_episodes = 1000\n",
        "t_max = 10\n",
        "\n",
        "# Setup the q functions now\n",
        "q_stay = np.zeros((max_brains+1,max_shotguns+1))\n",
        "q_roll = np.zeros((max_brains+1,max_shotguns+1))\n",
        "\n",
        "#note that now the visits depend on the action you took.\n",
        "visits_stay = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "visits_roll = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "\n",
        "#policy! fixed for now.\n",
        "policy = np.zeros((max_brains+1,max_shotguns+1),dtype=int) #where to roll again and where to stop.\n",
        "brains,shotguns = np.indices((max_brains+1,max_shotguns+1))\n",
        "policy[brains,shotguns] = (brains < 5) #reroll if brains<5 otherwise stop\n",
        "\n",
        "#Main Monte Carlo Loop\n",
        "verbose = False\n",
        "for episode in tqdm(range(num_episodes)):\n",
        "\n",
        "  policy = (q_roll >= q_stay)\n",
        "\n",
        "  #Initialize Episode\n",
        "  if verbose: print(f\"Episode #{episode}...\")\n",
        "  this_episode_visits_stay = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "  this_episode_visits_roll = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "  my_history = dice_roll_history()\n",
        "  brain_state = int(0) #starting state of the number of brains, shotguns we've seen.\n",
        "  shotgun_state = int(0)\n",
        "\n",
        "  #Loop over times t\n",
        "  for t in range(t_max):\n",
        "    if verbose: print(f\".{t=}, Brains:{brain_state}, Shotguns:{shotgun_state}\")\n",
        "\n",
        "    #get the action from the policy\n",
        "    action = policy[brain_state, shotgun_state]\n",
        "\n",
        "\n",
        "    if action == 1:\n",
        "      if verbose: print(f\"..Chose to Reroll! Roll={num_to_words(my_history[t])}\")\n",
        "      this_episode_visits_roll[brain_state,shotgun_state] += 1\n",
        "\n",
        "      #chose to roll again!\n",
        "      num_brains = np.sum(my_history[t] == 0)\n",
        "      num_shotguns = np.sum(my_history[t] == 1)\n",
        "      brain_state = min(max_brains, brain_state+num_brains)\n",
        "      shotgun_state += num_shotguns\n",
        "\n",
        "      if shotgun_state > max_shotguns:\n",
        "        if verbose:print(\"Went bust :(\")\n",
        "        break\n",
        "\n",
        "    elif action == 0:\n",
        "      this_episode_visits_stay[brain_state,shotgun_state] += 1\n",
        "      if verbose:print(f\"..Chose to Stop! Final Brains={brain_state}\")\n",
        "      #chose to stop\n",
        "      break\n",
        "\n",
        "  if shotgun_state <= max_shotguns:\n",
        "    reward = brain_state\n",
        "  else:\n",
        "    reward = 0\n",
        "\n",
        "  q_stay = np.where(this_episode_visits_stay,q_stay + 1/(visits_stay+1)*(reward - q_stay),q_stay)\n",
        "  visits_stay = np.where(this_episode_visits_stay,visits_stay+1,visits_stay)\n",
        "\n",
        "  q_roll = np.where(this_episode_visits_roll,q_roll+ 1/(visits_roll+1)*(reward - q_roll),q_roll)\n",
        "  visits_roll = np.where(this_episode_visits_roll,visits_roll+1,visits_roll)\n",
        "\n",
        "  if verbose:print(f\"{q_stay=}\")\n",
        "  if verbose:print(f\"{q_roll=}\")\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(f\"q_stay:\\n {q_stay}\")\n",
        "print(f\"visits_stay: \\n {visits_stay}\")\n",
        "print(f\"q_roll:\\n {q_roll}\")\n",
        "print(f\"visits_roll:\\n {visits_roll}\")\n",
        "\n",
        "print(f\"policy: \\n {policy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyIHR_Evv4nq",
        "outputId": "8a0ce2bd-1aae-4331-f24a-e74e8dba89b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:02<00:00, 490.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "q_stay:\n",
            " [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "visits_stay: \n",
            " [[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "q_roll:\n",
            " [[0.01 0.   0.  ]\n",
            " [0.   0.   0.  ]\n",
            " [0.   0.04 0.  ]\n",
            " [0.   0.   0.  ]\n",
            " [0.   0.08 0.  ]\n",
            " [0.   0.   0.  ]\n",
            " [0.   0.23 0.  ]\n",
            " [0.   0.   0.  ]\n",
            " [0.   0.69 0.  ]\n",
            " [0.   0.9  0.  ]]\n",
            "visits_roll:\n",
            " [[1000   80   85]\n",
            " [ 141  269  178]\n",
            " [ 141  237  158]\n",
            " [  92  125  161]\n",
            " [  42  112  133]\n",
            " [  33   70  112]\n",
            " [  12   39   79]\n",
            " [   3   28   65]\n",
            " [   6   13   42]\n",
            " [   2   10   34]]\n",
            "policy: \n",
            " [[ True  True  True]\n",
            " [ True  True  True]\n",
            " [ True  True  True]\n",
            " [ True  True  True]\n",
            " [ True  True  True]\n",
            " [ True  True  True]\n",
            " [ True  True  True]\n",
            " [ True  True  True]\n",
            " [ True  True  True]\n",
            " [ True  True  True]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Epsilon Greedy Learning"
      ],
      "metadata": {
        "id": "UJKSyiORVzyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def epsilon_random(policy_action,epsilon):\n",
        "  if np.random.random() < epsilon: #with probability epislon, make it purely random\n",
        "    return np.random.randint(2)\n",
        "  else: #otherwise return the policy\n",
        "    return policy_action"
      ],
      "metadata": {
        "id": "Y4kb1suAV41y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Policy improvement!\n",
        "\n",
        "# Setup number of episodes and maximum length of an episode\n",
        "num_episodes = 10_000\n",
        "t_max = 10\n",
        "\n",
        "# Setup the q functions now\n",
        "q_stay = np.zeros((max_brains+1,max_shotguns+1))\n",
        "q_roll = np.zeros((max_brains+1,max_shotguns+1))\n",
        "\n",
        "#note that now the visits depend on the action you took.\n",
        "visits_stay = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "visits_roll = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "\n",
        "#policy! fixed for now.\n",
        "policy = np.zeros((max_brains+1,max_shotguns+1),dtype=int) #where to roll again and where to stop.\n",
        "brains,shotguns = np.indices((max_brains+1,max_shotguns+1))\n",
        "policy[brains,shotguns] = (brains < 5) #reroll if brains<5 otherwise stop\n",
        "\n",
        "#Main Monte Carlo Loop\n",
        "verbose = False\n",
        "for episode in tqdm(range(num_episodes)):\n",
        "\n",
        "  policy = (q_roll >= q_stay)\n",
        "\n",
        "  #Initialize Episode\n",
        "  if verbose: print(f\"Episode #{episode}...\")\n",
        "  this_episode_visits_stay = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "  this_episode_visits_roll = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "  my_history = dice_roll_history()\n",
        "  brain_state = int(0) #starting state of the number of brains, shotguns we've seen.\n",
        "  shotgun_state = int(0)\n",
        "\n",
        "  #Loop over times t\n",
        "  for t in range(t_max):\n",
        "    if verbose: print(f\".{t=}, Brains:{brain_state}, Shotguns:{shotgun_state}\")\n",
        "\n",
        "    #get the action from the policy\n",
        "    if episode < 5000:\n",
        "      epsilon = 0.5\n",
        "    else:\n",
        "      epsilon = 0.05\n",
        "    action = epsilon_random(policy[brain_state, shotgun_state],epsilon)\n",
        "\n",
        "\n",
        "    if action == 1:\n",
        "      if verbose: print(f\"..Chose to Reroll! Roll={num_to_words(my_history[t])}\")\n",
        "      this_episode_visits_roll[brain_state,shotgun_state] += 1\n",
        "\n",
        "      #chose to roll again!\n",
        "      num_brains = np.sum(my_history[t] == 0)\n",
        "      num_shotguns = np.sum(my_history[t] == 1)\n",
        "      brain_state = min(max_brains, brain_state+num_brains)\n",
        "      shotgun_state += num_shotguns\n",
        "\n",
        "      if shotgun_state > max_shotguns:\n",
        "        if verbose:print(\"Went bust :(\")\n",
        "        break\n",
        "\n",
        "    elif action == 0:\n",
        "      this_episode_visits_stay[brain_state,shotgun_state] += 1\n",
        "      if verbose:print(f\"..Chose to Stop! Final Brains={brain_state}\")\n",
        "      #chose to stop\n",
        "      break\n",
        "\n",
        "  if shotgun_state <= max_shotguns:\n",
        "    reward = brain_state\n",
        "  else:\n",
        "    reward = 0\n",
        "\n",
        "  q_stay = np.where(this_episode_visits_stay,q_stay + 1/(visits_stay+1)*(reward - q_stay),q_stay)\n",
        "  visits_stay = np.where(this_episode_visits_stay,visits_stay+1,visits_stay)\n",
        "\n",
        "  q_roll = np.where(this_episode_visits_roll,q_roll+ 1/(visits_roll+1)*(reward - q_roll),q_roll)\n",
        "  visits_roll = np.where(this_episode_visits_roll,visits_roll+1,visits_roll)\n",
        "\n",
        "  if verbose:print(f\"{q_stay=}\")\n",
        "  if verbose:print(f\"{q_roll=}\")\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(f\"q_stay:\\n {q_stay}\")\n",
        "print(f\"visits_stay: \\n {visits_stay}\")\n",
        "print(f\"q_roll:\\n {q_roll}\")\n",
        "print(f\"visits_roll:\\n {visits_roll}\")\n",
        "\n",
        "print(f\"policy: \\n {1.0*policy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjrNgpKWV3vL",
        "outputId": "2b0318a5-c0ed-41a9-b843-9900029a8726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:17<00:00, 573.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "q_stay:\n",
            " [[0. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [2. 2. 2.]\n",
            " [3. 3. 3.]\n",
            " [4. 4. 4.]\n",
            " [5. 5. 5.]\n",
            " [6. 6. 6.]\n",
            " [7. 7. 7.]\n",
            " [8. 8. 8.]\n",
            " [9. 9. 9.]]\n",
            "visits_stay: \n",
            " [[1405  101   97]\n",
            " [ 134  286 1266]\n",
            " [ 167  295  931]\n",
            " [  93  200  853]\n",
            " [  29  668  460]\n",
            " [  18  310  189]\n",
            " [   7  109   46]\n",
            " [   6   39   27]\n",
            " [  21   17    6]\n",
            " [   4    3    4]]\n",
            "q_roll:\n",
            " [[1.97 1.28 0.54]\n",
            " [2.65 1.89 0.87]\n",
            " [3.39 2.47 1.39]\n",
            " [4.34 3.22 1.81]\n",
            " [5.29 3.34 1.3 ]\n",
            " [6.   3.77 2.19]\n",
            " [7.06 4.25 1.88]\n",
            " [7.14 4.5  2.33]\n",
            " [0.   5.67 4.  ]\n",
            " [6.75 4.5  0.  ]]\n",
            "visits_roll:\n",
            " [[8644  805  736]\n",
            " [ 979 1905  163]\n",
            " [1237 1560  111]\n",
            " [ 620  798  108]\n",
            " [ 238   71   46]\n",
            " [ 146   35   21]\n",
            " [  81    4    8]\n",
            " [  29    4    3]\n",
            " [   0    3    2]\n",
            " [   4    2    3]]\n",
            "policy: \n",
            " [[1. 1. 1.]\n",
            " [1. 1. 0.]\n",
            " [1. 1. 0.]\n",
            " [1. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Off Policy Learning - Policy Improvement"
      ],
      "metadata": {
        "id": "2vW973Q_Vw4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A simple off policy policy improvement:\n",
        "# Never Stop Rolling, *but* imagine what WOULD have happened if you chose to stop or roll again according to your\n",
        "\n",
        "# Setup number of episodes and maximum length of an episode\n",
        "num_episodes = 1000\n",
        "t_max = 10\n",
        "\n",
        "# Setup the q functions now\n",
        "q_stay = np.zeros((max_brains+1,max_shotguns+1))\n",
        "q_roll = np.zeros((max_brains+1,max_shotguns+1))\n",
        "\n",
        "#note that now the visits depend on the action you took.\n",
        "visits_stay = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "visits_roll = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "\n",
        "#policy! fixed for now.\n",
        "policy = np.zeros((max_brains+1,max_shotguns+1),dtype=int) #where to roll again and where to stop.\n",
        "brains,shotguns = np.indices((max_brains+1,max_shotguns+1))\n",
        "policy[brains,shotguns] = (brains < 5) #reroll if brains<5 otherwise stop\n",
        "\n",
        "#Main Monte Carlo Loop\n",
        "verbose = False\n",
        "for episode in tqdm(range(num_episodes)):\n",
        "\n",
        "  policy = (q_roll > q_stay)\n",
        "\n",
        "  #Initialize Episode\n",
        "  if verbose: print(f\"Episode #{episode}...\")\n",
        "  this_episode_visits_stay = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "  this_episode_visits_roll = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "  my_history = dice_roll_history()\n",
        "  brain_state = int(0) #starting state of the number of brains, shotguns we've seen.\n",
        "  shotgun_state = int(0)\n",
        "\n",
        "  #Loop over times t\n",
        "  for t in range(t_max):\n",
        "    if verbose: print(f\".{t=}, Brains:{brain_state}, Shotguns:{shotgun_state}\")\n",
        "\n",
        "    #get the action from the policy\n",
        "\n",
        "    action = policy[brain_state, shotgun_state]\n",
        "\n",
        "    if action == 1:\n",
        "      if verbose: print(f\"..Chose to Reroll! Roll={num_to_words(my_history[t])}\")\n",
        "      this_episode_visits_roll[brain_state,shotgun_state] += 1\n",
        "\n",
        "      #chose to roll again!\n",
        "      num_brains = np.sum(my_history[t] == 0)\n",
        "      num_shotguns = np.sum(my_history[t] == 1)\n",
        "      brain_state = min(max_brains, brain_state+num_brains)\n",
        "      shotgun_state += num_shotguns\n",
        "\n",
        "\n",
        "      if shotgun_state > max_shotguns:\n",
        "        if verbose:print(\"Went bust :(\")\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "    elif action == 0:\n",
        "      #this_episode_visits_stay[brain_state,shotgun_state] += 1\n",
        "      if verbose:print(f\"..Chose to Stop! Final Brains={brain_state}\")\n",
        "      this_episode_visits_stay[brain_state,shotgun_state] += 1\n",
        "      #break\n",
        "      reward = brain_state\n",
        "      q_stay = np.where(this_episode_visits_stay,q_stay + 1/(visits_stay+1)*(reward - q_stay),q_stay)\n",
        "      visits_stay = np.where(this_episode_visits_stay,visits_stay+1,visits_stay)\n",
        "      q_roll = np.where(this_episode_visits_roll,q_roll+ 1/(visits_roll+1)*(reward - q_roll),q_roll)\n",
        "      visits_roll = np.where(this_episode_visits_roll,visits_roll+1,visits_roll)\n",
        "      this_episode_visits_stay = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "      this_episode_visits_roll = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "\n",
        "      if verbose: print(f\"..Simulating rolling again anyways! Roll={num_to_words(my_history[t])}\")\n",
        "      this_episode_visits_roll[brain_state,shotgun_state] += 1\n",
        "\n",
        "      #chose to roll again!\n",
        "      num_brains = np.sum(my_history[t] == 0)\n",
        "      num_shotguns = np.sum(my_history[t] == 1)\n",
        "      brain_state = min(max_brains, brain_state+num_brains)\n",
        "      shotgun_state += num_shotguns\n",
        "\n",
        "\n",
        "      if shotgun_state > max_shotguns:\n",
        "        if verbose:print(\"Went bust :(\")\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "  if shotgun_state <= max_shotguns:\n",
        "    reward = brain_state\n",
        "  else:\n",
        "    reward = 0\n",
        "\n",
        "  q_stay = np.where(this_episode_visits_stay,q_stay + 1/(visits_stay+1)*(reward - q_stay),q_stay)\n",
        "  visits_stay = np.where(this_episode_visits_stay,visits_stay+1,visits_stay)\n",
        "\n",
        "  q_roll = np.where(this_episode_visits_roll,q_roll+ 1/(visits_roll+1)*(reward - q_roll),q_roll)\n",
        "  visits_roll = np.where(this_episode_visits_roll,visits_roll+1,visits_roll)\n",
        "\n",
        "  if verbose:print(f\"{q_stay=}\")\n",
        "  if verbose:print(f\"{q_roll=}\")\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(f\"q_stay:\\n {q_stay}\")\n",
        "print(f\"visits_stay: \\n {visits_stay}\")\n",
        "print(f\"q_roll:\\n {q_roll}\")\n",
        "print(f\"visits_roll:\\n {visits_roll}\")\n",
        "\n",
        "print(f\"policy: \\n {1.0*policy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW598RoCJJQa",
        "outputId": "76da721c-a15a-4084-fedb-f9605fe4742a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:01<00:00, 535.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "q_stay:\n",
            " [[0. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [2. 2. 2.]\n",
            " [3. 3. 3.]\n",
            " [4. 4. 4.]\n",
            " [5. 5. 5.]\n",
            " [6. 6. 6.]\n",
            " [7. 7. 7.]\n",
            " [8. 8. 8.]\n",
            " [9. 9. 9.]]\n",
            "visits_stay: \n",
            " [[  2   1   2]\n",
            " [  1   3 172]\n",
            " [  1   6 169]\n",
            " [  1  45 173]\n",
            " [  1   7 156]\n",
            " [  1  76 106]\n",
            " [  3  35  88]\n",
            " [  2  20  54]\n",
            " [  1  11  47]\n",
            " [  9  23  49]]\n",
            "q_roll:\n",
            " [[2.24 1.46 0.69]\n",
            " [3.09 2.14 0.89]\n",
            " [3.72 2.76 1.18]\n",
            " [4.52 3.44 1.49]\n",
            " [5.25 4.65 1.73]\n",
            " [5.57 4.62 2.19]\n",
            " [6.46 5.07 2.93]\n",
            " [7.86 6.55 2.55]\n",
            " [8.57 6.27 2.47]\n",
            " [8.   7.04 1.84]]\n",
            "visits_roll:\n",
            " [[1000  111   98]\n",
            " [ 116  267  188]\n",
            " [ 163  214  169]\n",
            " [  96  132  173]\n",
            " [  32  110  156]\n",
            " [  30   77  106]\n",
            " [  13   40   88]\n",
            " [   7   29   55]\n",
            " [   7   11   47]\n",
            " [   9   23   49]]\n",
            "policy: \n",
            " [[1. 1. 1.]\n",
            " [1. 1. 0.]\n",
            " [1. 1. 0.]\n",
            " [1. 1. 0.]\n",
            " [1. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzYAW93cydtK",
        "outputId": "c36fb4c1-0f7a-4e0a-cdc7-7544111cab66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ True  True  True]\n",
            " [ True  True False]\n",
            " [ True  True False]\n",
            " [ True  True False]\n",
            " [ True  True False]\n",
            " [ True False False]\n",
            " [ True False False]\n",
            " [ True False False]\n",
            " [ True False False]\n",
            " [False False False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qNozSw322XY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. No policy change\n",
        "2. Greedy policy improvment -> Gets stuck!\n",
        "3. \"Optimism in the face of uncertainty\"\n",
        "4. Alpha improvements = Slowly delete history\n",
        "5. Epsilon Greedy Improvements"
      ],
      "metadata": {
        "id": "cgDEbTGsN-HE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2PTxHENQUlC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Policy improvement!\n",
        "\n",
        "# Setup number of episodes and maximum length of an episode\n",
        "num_episodes = 10_000\n",
        "t_max = 10\n",
        "\n",
        "# Setup the q functions now\n",
        "q_stay = np.zeros((max_brains+1,max_shotguns+1))\n",
        "q_roll = np.zeros((max_brains+1,max_shotguns+1))\n",
        "\n",
        "#note that now the visits depend on the action you took.\n",
        "visits_stay = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "visits_roll = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "\n",
        "#policy! fixed for now.\n",
        "policy = np.zeros((max_brains+1,max_shotguns+1),dtype=int) #where to roll again and where to stop.\n",
        "brains,shotguns = np.indices((max_brains+1,max_shotguns+1))\n",
        "policy[brains,shotguns] = (brains < 5) #reroll if brains<5 otherwise stop\n",
        "\n",
        "#Main Monte Carlo Loop\n",
        "verbose = False\n",
        "for episode in tqdm(range(num_episodes)):\n",
        "  if (episode+1) % 10 == 0:\n",
        "    policy = 1*(q_roll >= q_stay)\n",
        "  #Initialize Episode\n",
        "  if verbose: print(f\"Episode #{episode}...\")\n",
        "  this_episode_visits_stay = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "  this_episode_visits_roll = np.zeros((max_brains+1,max_shotguns+1),dtype=int)\n",
        "  my_history = dice_roll_history()\n",
        "  brain_state = int(0) #starting state of the number of brains, shotguns we've seen.\n",
        "  shotgun_state = int(0)\n",
        "\n",
        "  #Loop over times t\n",
        "  for t in range(t_max):\n",
        "    if verbose: print(f\".{t=}, Brains:{brain_state}, Shotguns:{shotgun_state}\")\n",
        "\n",
        "    #get the action from the policy\n",
        "    action = policy[brain_state, shotgun_state]\n",
        "\n",
        "    epsilon = 5.0/np.sqrt(episode+1)\n",
        "    if np.random.random() < epsilon:\n",
        "      action = np.random.randint(2) #random choice sometimes!\n",
        "\n",
        "\n",
        "\n",
        "    if action == 1:\n",
        "      if verbose: print(f\"..Chose to Reroll! Roll={num_to_words(my_history[t])}\")\n",
        "      this_episode_visits_roll[brain_state,shotgun_state] += 1\n",
        "\n",
        "      #chose to roll again!\n",
        "      num_brains = np.sum(my_history[t] == 0)\n",
        "      num_shotguns = np.sum(my_history[t] == 1)\n",
        "      brain_state = min(max_brains, brain_state+num_brains)\n",
        "      shotgun_state += num_shotguns\n",
        "\n",
        "      if shotgun_state > max_shotguns:\n",
        "        if verbose:print(\"Went bust :(\")\n",
        "        break\n",
        "\n",
        "    elif action == 0:\n",
        "      this_episode_visits_stay[brain_state,shotgun_state] += 1\n",
        "      if verbose:print(f\"..Chose to Stop! Final Brains={brain_state}\")\n",
        "      #chose to stop\n",
        "      break\n",
        "\n",
        "  if shotgun_state <= max_shotguns:\n",
        "    reward = brain_state\n",
        "  else:\n",
        "    reward = 0\n",
        "\n",
        "  alpha = 0.05\n",
        "  q_stay = np.where(this_episode_visits_stay,q_stay + np.maximum(1/(visits_stay+1),alpha)*(reward - q_stay),q_stay)\n",
        "  visits_stay = np.where(this_episode_visits_stay,visits_stay+1,visits_stay)\n",
        "\n",
        "  q_roll = np.where(this_episode_visits_roll,q_roll+ np.maximum(1/(visits_roll+1),alpha)*(reward - q_roll),q_roll)\n",
        "  visits_roll = np.where(this_episode_visits_roll,visits_roll+1,visits_roll)\n",
        "\n",
        "  if verbose:print(f\"{q_stay=}\")\n",
        "  if verbose:print(f\"{q_roll=}\")\n",
        "\n",
        "print(\"\")\n",
        "print(f\"q_stay:\\n {q_stay}\")\n",
        "print(f\"visits_stay: \\n {visits_stay}\")\n",
        "print(f\"q_roll:\\n {q_roll}\")\n",
        "print(f\"visits_roll:\\n {visits_roll}\")\n",
        "\n",
        "print(f\"policy:\\n {policy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB08G7ovURUX",
        "outputId": "752f1be6-e1e3-49c1-f1c8-49df434e23eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:17<00:00, 565.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "q_stay:\n",
            " [[0. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [2. 2. 2.]\n",
            " [3. 3. 3.]\n",
            " [4. 4. 4.]\n",
            " [5. 5. 5.]\n",
            " [6. 6. 6.]\n",
            " [0. 7. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 9.]]\n",
            "visits_stay: \n",
            " [[ 494   70   37]\n",
            " [  61  109 1509]\n",
            " [ 132  732 1158]\n",
            " [  51  850  894]\n",
            " [  50  732  375]\n",
            " [ 167  263   80]\n",
            " [  67   44    7]\n",
            " [   0   13    0]\n",
            " [   0    0    0]\n",
            " [   0    0    8]]\n",
            "q_roll:\n",
            " [[2.66 1.3  0.62]\n",
            " [2.53 2.   0.77]\n",
            " [3.47 1.98 1.83]\n",
            " [4.41 2.99 1.14]\n",
            " [5.02 3.67 0.8 ]\n",
            " [4.89 4.54 0.  ]\n",
            " [5.43 2.5  0.  ]\n",
            " [4.75 0.   3.6 ]\n",
            " [9.   1.8  0.  ]\n",
            " [6.75 0.   0.  ]]\n",
            "visits_roll:\n",
            " [[9524  885  917]\n",
            " [1220 2257   98]\n",
            " [1444 1379   45]\n",
            " [ 818  270   42]\n",
            " [ 286   31   15]\n",
            " [  18   13    4]\n",
            " [   7   12    1]\n",
            " [  12    2   10]\n",
            " [   2    5    8]\n",
            " [   4    4    1]]\n",
            "policy:\n",
            " [[1 1 1]\n",
            " [1 1 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 1]\n",
            " [1 1 1]\n",
            " [1 1 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lo1N-vUKUVsH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}